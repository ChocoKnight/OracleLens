{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11786001,
          "sourceType": "datasetVersion",
          "datasetId": 7400065
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "TeamStatPredictions",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "jfnjhsq5fxwr"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "kevinwtan_leagueoflegendsmatchperformancepredictions_path = kagglehub.dataset_download('kevinwtan/leagueoflegendsmatchperformancepredictions')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "i0k2Jot2fxwx"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "YnT13Idnfxwy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import sklearn"
      ],
      "metadata": {
        "trusted": true,
        "id": "BzKfmQ8Pfxw0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "trusted": true,
        "id": "JFHELIFTfxw2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"/kaggle/input/leagueoflegendsmatchperformancepredictions/team_match_dataset.jsonl\", split=\"train\")\n",
        "\n",
        "len(dataset[0][\"past_values\"]), len(dataset[0][\"future_values\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "ImDNyPXdfxw4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "test_dataset = split_dataset[\"test\"]"
      ],
      "metadata": {
        "trusted": true,
        "id": "j0xV6jc8fxw5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset), len(test_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "sjQt5OMvfxw6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(train_dataset[0][\"past_values\"]).shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "J7XJwEkpfxw7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_features = np.vstack([\n",
        "    np.array(entry[\"past_values\"] + entry[\"future_values\"])\n",
        "    for entry in train_dataset\n",
        "])\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(train_features)\n",
        "\n",
        "print(train_features.shape)\n",
        "\n",
        "def scale_example(example):\n",
        "    example[\"past_values\"] = scaler.transform(np.array(example[\"past_values\"])).tolist()\n",
        "    example[\"future_values\"] = scaler.transform(np.array(example[\"future_values\"])).tolist()\n",
        "    return example\n",
        "\n",
        "scaled_train_dataset = train_dataset.map(scale_example)\n",
        "scaled_test_dataset = test_dataset.map(scale_example)"
      ],
      "metadata": {
        "trusted": true,
        "id": "PL5jSdSlfxw_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "scaled_sample = scaled_train_dataset[0]\n",
        "np.array(scaled_sample[\"past_values\"]).mean(), np.array(scaled_sample[\"past_values\"]).std()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WKOGH12hfxxB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(scaled_train_dataset), len(scaled_test_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "id": "19UQgJ-vfxxC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
        "\n",
        "feature_size = len(train_dataset[0][\"past_values\"][0])  # Size of a single feature vector\n",
        "\n",
        "# Define the configuration for the model\n",
        "configuration = TimeSeriesTransformerConfig(\n",
        "    prediction_length=1,\n",
        "    context_length=10,\n",
        "    input_size=feature_size,\n",
        "    lags_sequence=[1]\n",
        ")\n",
        "\n",
        "# Initialize the model with the configuration\n",
        "model = TimeSeriesTransformerModel(configuration)\n",
        "\n",
        "# Get the model's configuration\n",
        "configuration = model.config"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T20:42:14.778836Z",
          "iopub.execute_input": "2025-05-13T20:42:14.779172Z",
          "iopub.status.idle": "2025-05-13T20:42:35.30325Z",
          "shell.execute_reply.started": "2025-05-13T20:42:14.779149Z",
          "shell.execute_reply": "2025-05-13T20:42:35.302316Z"
        },
        "id": "PP32znCXfxxD",
        "outputId": "a9998da2-5b56-4911-ccb2-b12e86499bc4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-05-13 20:42:19.158846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747168939.612342      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747168939.742266      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.dataset[idx]\n",
        "        return {\n",
        "            \"past_values\": torch.tensor(entry[\"past_values\"], dtype=torch.float32),\n",
        "            \"future_values\": torch.tensor(entry[\"future_values\"], dtype=torch.float32),\n",
        "        }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T20:42:35.304191Z",
          "iopub.execute_input": "2025-05-13T20:42:35.304729Z",
          "iopub.status.idle": "2025-05-13T20:42:35.309673Z",
          "shell.execute_reply.started": "2025-05-13T20:42:35.304709Z",
          "shell.execute_reply": "2025-05-13T20:42:35.308989Z"
        },
        "id": "62QGO3yQfxxD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(TimeSeriesDataset(scaled_train_dataset), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TimeSeriesDataset(scaled_test_dataset), batch_size=32)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RFLk2rwtfxxE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTMForecaster(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "        super(LSTMForecaster, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)  # x: [batch, seq_len, input_size]\n",
        "        out = self.fc(lstm_out[:, -1, :])  # last time step\n",
        "        return out"
      ],
      "metadata": {
        "trusted": true,
        "id": "Kjj9NRVrfxxF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print(torch.cuda.is_available())       # Should be True\n",
        "# print(torch.cuda.current_device())     # Should return 0 or a valid GPU id\n",
        "# print(torch.cuda.get_device_name(0))   # Should print your GPU name"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-26T05:40:53.790927Z",
          "iopub.execute_input": "2025-05-26T05:40:53.791151Z",
          "iopub.status.idle": "2025-05-26T05:40:53.799835Z",
          "shell.execute_reply.started": "2025-05-26T05:40:53.791135Z",
          "shell.execute_reply": "2025-05-26T05:40:53.799282Z"
        },
        "id": "ZIPQHwMmfxxG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = len(scaled_train_dataset[0][\"past_values\"][0])\n",
        "output_size = len(scaled_train_dataset[0][\"future_values\"][0])\n",
        "\n",
        "input_size, output_size"
      ],
      "metadata": {
        "trusted": true,
        "id": "09iP-kcffxxG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "input_size = len(scaled_train_dataset[0][\"past_values\"][0])\n",
        "output_size = len(scaled_train_dataset[0][\"future_values\"][0])\n",
        "model = LSTMForecaster(input_size=input_size, hidden_size=64, num_layers=5, output_size=output_size)\n",
        "\n",
        "lr = 1e-4\n",
        "wd = 1e-3\n",
        "epochs = 5\n",
        "\n",
        "train_mses = []\n",
        "test_mses = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "opt = AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader))\n",
        "    for batch in train_loader:\n",
        "        past = batch[\"past_values\"].to(device)  # shape: [batch, seq_len, input_size]\n",
        "        future = batch[\"future_values\"].to(device)  # shape: [batch, output_size]\n",
        "\n",
        "        opt.zero_grad()\n",
        "        preds = model(past)\n",
        "        # loss = loss_fn(preds, future)\n",
        "        loss = loss_fn(preds, future.squeeze(1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Eval\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        pbar = tqdm(total=len(test_loader))\n",
        "        for batch in test_loader:\n",
        "            past = batch[\"past_values\"].to(device)\n",
        "            future = batch[\"future_values\"].to(device)\n",
        "            preds = model(past)\n",
        "            test_loss += loss_fn(preds, future.squeeze(1)).item()\n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "        print(f\"Epoch {epoch+1}, Test Loss: {test_loss / len(test_loader):.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T20:42:49.79175Z",
          "iopub.execute_input": "2025-05-13T20:42:49.792053Z",
          "iopub.status.idle": "2025-05-13T20:54:59.462732Z",
          "shell.execute_reply.started": "2025-05-13T20:42:49.792034Z",
          "shell.execute_reply": "2025-05-13T20:54:59.461853Z"
        },
        "id": "heT6wu28fxxH",
        "outputId": "6591e6d9-730e-48c9-d876-8edb54b2847a"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:58<00:00, 19.83it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1, Train Loss: 0.6504\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.25it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1, Test Loss: 0.5795\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:58<00:00, 20.03it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2, Train Loss: 0.5281\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.66it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2, Test Loss: 0.5175\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:58<00:00, 19.85it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3, Train Loss: 0.5109\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.20it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3, Test Loss: 0.5144\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:58<00:00, 20.03it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4, Train Loss: 0.5091\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.29it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4, Test Loss: 0.5133\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:58<00:00, 20.07it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5, Train Loss: 0.5079\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.56it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5, Test Loss: 0.5122\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:58<00:00, 20.07it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6, Train Loss: 0.5066\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.53it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6, Test Loss: 0.5105\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:57<00:00, 20.21it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7, Train Loss: 0.5051\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.21it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7, Test Loss: 0.5100\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [00:57<00:00, 20.32it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8, Train Loss: 0.5043\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:13<00:00, 21.37it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8, Test Loss: 0.5092\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:03<00:00, 18.46it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9, Train Loss: 0.5037\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.13it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9, Test Loss: 0.5088\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.79it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10, Train Loss: 0.5033\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.00it/s]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10, Test Loss: 0.5082\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"lstm_rnn_model_1.pth\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T21:03:27.660183Z",
          "iopub.execute_input": "2025-05-13T21:03:27.660775Z",
          "iopub.status.idle": "2025-05-13T21:03:27.668452Z",
          "shell.execute_reply.started": "2025-05-13T21:03:27.660754Z",
          "shell.execute_reply": "2025-05-13T21:03:27.667684Z"
        },
        "id": "--bcDsqAfxxI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "min(min(scaled_train_dataset[0][\"past_values\"])), max(max(scaled_train_dataset[0][\"past_values\"])), min(min(scaled_train_dataset[0][\"future_values\"])), max(max(scaled_train_dataset[0][\"future_values\"]))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-12T20:01:32.408304Z",
          "iopub.execute_input": "2025-05-12T20:01:32.408959Z",
          "iopub.status.idle": "2025-05-12T20:01:32.423097Z",
          "shell.execute_reply.started": "2025-05-12T20:01:32.408932Z",
          "shell.execute_reply": "2025-05-12T20:01:32.422264Z"
        },
        "id": "d2ZIHJH1fxxJ",
        "outputId": "f462031e-f7d1-47bb-ac84-23560d8a97e8"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(-1.6223253693462107,\n 5.619866001845678,\n -1.6223253693462107,\n 5.619866001845678)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(next(model.parameters()).device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-12T20:30:24.574775Z",
          "iopub.execute_input": "2025-05-12T20:30:24.575288Z",
          "iopub.status.idle": "2025-05-12T20:30:24.579919Z",
          "shell.execute_reply.started": "2025-05-12T20:30:24.575268Z",
          "shell.execute_reply": "2025-05-12T20:30:24.578917Z"
        },
        "id": "8cIz7tf4fxxL",
        "outputId": "8ece59c4-663a-4dd9-8ba8-a464fcf1ea64"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-12T20:30:26.032673Z",
          "iopub.execute_input": "2025-05-12T20:30:26.03327Z",
          "iopub.status.idle": "2025-05-12T20:30:26.320005Z",
          "shell.execute_reply.started": "2025-05-12T20:30:26.033249Z",
          "shell.execute_reply": "2025-05-12T20:30:26.31898Z"
        },
        "id": "kGGjqpXPfxxL",
        "outputId": "74f9b4c7-43af-473a-d413-0d4853181bd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mon May 12 20:30:26 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   61C    P0             29W /   70W |     225MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   37C    P8              9W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "input_size = len(scaled_train_dataset[0][\"past_values\"][0])\n",
        "output_size = len(scaled_train_dataset[0][\"future_values\"][0])\n",
        "model = LSTMForecaster(input_size=input_size, hidden_size=128, num_layers=10, output_size=output_size)\n",
        "\n",
        "lr = 1e-4\n",
        "wd = 1e-3\n",
        "\n",
        "train_mses = []\n",
        "test_mses = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "opt = AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    pbar = tqdm(total=len(train_loader))\n",
        "    for batch in train_loader:\n",
        "        # past = batch[\"past_values\"].to(device)  # shape: [batch, seq_len, input_size]\n",
        "        past = torch.tensor(batch[\"past_values\"], dtype=torch.float32).to(device)\n",
        "        # future = batch[\"future_values\"].to(device)  # shape: [batch, output_size]\n",
        "        future = torch.tensor(batch[\"future_values\"], dtype=torch.float32).to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        preds = model(past)\n",
        "        # loss = loss_fn(preds, future)\n",
        "        loss = loss_fn(preds, future.squeeze(1))\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "        pbar.update(1)\n",
        "    pbar.close()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}, Train Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Eval\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        pbar = tqdm(total=len(test_loader))\n",
        "        for batch in test_loader:\n",
        "            past = batch[\"past_values\"].to(device)\n",
        "            future = batch[\"future_values\"].to(device)\n",
        "            preds = model(past)\n",
        "            test_loss += loss_fn(preds, future.squeeze(1)).item()\n",
        "            pbar.update(1)\n",
        "        pbar.close()\n",
        "        print(f\"Epoch {epoch+1}, Test Loss: {test_loss / len(test_loader):.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T21:39:03.989614Z",
          "iopub.execute_input": "2025-05-13T21:39:03.989904Z",
          "iopub.status.idle": "2025-05-13T22:00:51.81012Z",
          "shell.execute_reply.started": "2025-05-13T21:39:03.989882Z",
          "shell.execute_reply": "2025-05-13T22:00:51.80903Z"
        },
        "id": "WIQ1-MkSfxxM",
        "outputId": "02820ddb-fd41-4120-b307-280c120f96c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "  0%|          | 0/1167 [00:00<?, ?it/s]/tmp/ipykernel_31/3101085749.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  past = torch.tensor(batch[\"past_values\"], dtype=torch.float32).to(device)\n/tmp/ipykernel_31/3101085749.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  future = torch.tensor(batch[\"future_values\"], dtype=torch.float32).to(device)\n100%|██████████| 1167/1167 [01:02<00:00, 18.73it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1, Train Loss: 0.6683\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.46it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1, Test Loss: 0.6464\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2, Train Loss: 0.6202\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.65it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2, Test Loss: 0.6193\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.74it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3, Train Loss: 0.5719\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.05it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3, Test Loss: 0.5166\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.72it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4, Train Loss: 0.5094\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.31it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4, Test Loss: 0.5127\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5, Train Loss: 0.5071\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.12it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5, Test Loss: 0.5111\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.90it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6, Train Loss: 0.5142\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.78it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6, Test Loss: 0.5124\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7, Train Loss: 0.5066\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.34it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7, Test Loss: 0.5111\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.88it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8, Train Loss: 0.5061\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.70it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8, Test Loss: 0.5107\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.86it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9, Train Loss: 0.5063\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.78it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9, Test Loss: 0.5116\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.83it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10, Train Loss: 0.5060\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 19.77it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10, Test Loss: 0.5104\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.82it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 11, Train Loss: 0.5055\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.55it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 11, Test Loss: 0.5101\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.60it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 12, Train Loss: 0.5048\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.38it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 12, Test Loss: 0.5106\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 19.00it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 13, Train Loss: 0.5045\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.53it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 13, Test Loss: 0.5093\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.85it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 14, Train Loss: 0.5042\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.75it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 14, Test Loss: 0.5096\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.78it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 15, Train Loss: 0.5041\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.42it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 15, Test Loss: 0.5093\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:02<00:00, 18.62it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 16, Train Loss: 0.5041\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.81it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 16, Test Loss: 0.5110\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1167/1167 [01:01<00:00, 18.89it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 17, Train Loss: 0.5038\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 292/292 [00:14<00:00, 20.36it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 17, Test Loss: 0.5092\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": " 17%|█▋        | 196/1167 [00:10<00:49, 19.47it/s]",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/3101085749.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# past = batch[\"past_values\"].to(device)  # shape: [batch, seq_len, input_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_31/3459767005.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         return {\n\u001b[1;32m     13\u001b[0m             \u001b[0;34m\"past_values\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"past_values\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2775\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2761\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2762\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2763\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLazyRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_size, output_size"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T22:01:20.140386Z",
          "iopub.execute_input": "2025-05-13T22:01:20.141183Z",
          "iopub.status.idle": "2025-05-13T22:01:20.145778Z",
          "shell.execute_reply.started": "2025-05-13T22:01:20.141156Z",
          "shell.execute_reply": "2025-05-13T22:01:20.145122Z"
        },
        "id": "Uys3unyWfxxN",
        "outputId": "10896eba-c443-400a-d91a-afc19466c521"
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(237, 237)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"lstm_rnn_model_128_10.pth\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T21:38:27.422371Z",
          "iopub.execute_input": "2025-05-13T21:38:27.422881Z",
          "iopub.status.idle": "2025-05-13T21:38:27.432877Z",
          "shell.execute_reply.started": "2025-05-13T21:38:27.422858Z",
          "shell.execute_reply": "2025-05-13T21:38:27.432137Z"
        },
        "id": "CV5ryIGFfxxO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate model with same architecture\n",
        "model = LSTMForecaster(input_size=..., hidden_size=..., num_layers=..., output_size=...)\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(torch.load(\"rnn_model.pth\"))\n",
        "\n",
        "# Move to GPU if needed\n",
        "model.to(device)\n",
        "model.eval()  # Set to evaluation mode if you're doing inference"
      ],
      "metadata": {
        "trusted": true,
        "id": "7EysX9CefxxP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    example = torch.tensor(some_input_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    prediction = model(example)"
      ],
      "metadata": {
        "trusted": true,
        "id": "MtpzrhLTfxxQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
        "\n",
        "feature_size = len(train_dataset[0][\"past_values\"][0])  # Size of a single feature vector\n",
        "\n",
        "# Define the configuration for the model\n",
        "configuration = TimeSeriesTransformerConfig(\n",
        "    prediction_length=1,\n",
        "    context_length=10,\n",
        "    input_size=feature_size,\n",
        "    lags_sequence=[1]\n",
        ")\n",
        "\n",
        "# Initialize the model with the configuration\n",
        "model = TimeSeriesTransformerModel(configuration)\n",
        "\n",
        "# Get the model's configuration\n",
        "configuration = model.config"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T22:01:31.224515Z",
          "iopub.execute_input": "2025-05-13T22:01:31.224978Z",
          "iopub.status.idle": "2025-05-13T22:01:31.245396Z",
          "shell.execute_reply.started": "2025-05-13T22:01:31.224957Z",
          "shell.execute_reply": "2025-05-13T22:01:31.244854Z"
        },
        "id": "9XVJdocefxxR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "lr = 1e-4\n",
        "wd = 1e-3\n",
        "epochs = 5\n",
        "\n",
        "opt = AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "loss_fn = torch.nn.MSELoss()\n",
        "\n",
        "train_mses = []\n",
        "test_mses = []\n",
        "\n",
        "best_test_mse = np.inf\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_loader:\n",
        "        opt.zero_grad()\n",
        "\n",
        "        past_values = batch[\"past_values\"].to(device)\n",
        "\n",
        "        future_values = batch[\"future_values\"].to(device)\n",
        "\n",
        "        past_observed_mask = torch.ones_like(past_values).to(device)\n",
        "        past_time_features = torch.zeros_like(past_values).to(device)\n",
        "        future_time_features = torch.zeros_like(past_values).to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            past_values=past_values,\n",
        "            past_time_features=past_time_features,\n",
        "            past_observed_mask=past_observed_mask,\n",
        "            future_values=future_values,\n",
        "            future_time_features=future_time_features\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(outputs.predictions, future_values)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0.0\n",
        "        for batch in val_loader:\n",
        "            past_values = batch[\"past_values\"].to(device)\n",
        "            future_values = batch[\"future_values\"].to(device)\n",
        "\n",
        "            outputs = model(past_values=past_values, future_values=future_values)\n",
        "            loss = loss_fn(outputs.predictions, future_values)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        print(f\"Epoch {epoch+1} - Val Loss: {avg_val_loss:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-13T22:01:35.29853Z",
          "iopub.execute_input": "2025-05-13T22:01:35.298806Z",
          "iopub.status.idle": "2025-05-13T22:01:35.940727Z",
          "shell.execute_reply.started": "2025-05-13T22:01:35.298787Z",
          "shell.execute_reply": "2025-05-13T22:01:35.939613Z"
        },
        "id": "TbgZJpZYfxxR",
        "outputId": "92048f7b-557e-420d-ef3d-6241e3aabf9b"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_31/786644787.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mfuture_time_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         outputs = model(\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mpast_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mpast_time_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_time_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, past_values, past_time_features, past_observed_mask, static_categorical_features, static_real_features, future_values, future_time_features, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, output_hidden_states, output_attentions, use_cache, return_dict)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         transformer_inputs, loc, scale, static_feat = self.create_network_inputs(\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0mpast_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0mpast_time_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_time_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py\u001b[0m in \u001b[0;36mcreate_network_inputs\u001b[0;34m(self, past_values, past_time_features, static_categorical_features, static_real_features, past_observed_mask, future_values, future_time_features)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m         )\n\u001b[0;32m-> 1295\u001b[0;31m         \u001b[0mlagged_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lagged_subsequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsequences_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsequences_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0mlags_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlagged_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[0mreshaped_lagged_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlagged_sequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlags_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlags_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/time_series_transformer/modeling_time_series_transformer.py\u001b[0m in \u001b[0;36mget_lagged_subsequences\u001b[0;34m(self, sequence, subsequences_length, shift)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msubsequences_length\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1226\u001b[0m                 \u001b[0;34mf\"lags cannot go further than history length, found lag {max(indices)} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 \u001b[0;34mf\"while history length is only {sequence_length}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: lags cannot go further than history length, found lag 1 while history length is only 11"
          ],
          "ename": "ValueError",
          "evalue": "lags cannot go further than history length, found lag 1 while history length is only 11",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"timeseries_transformer.pth\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "v6JMkgLifxxS"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}